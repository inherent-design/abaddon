Tree Evaluation Is in Space ğ‘‚ (log ğ‘› Â· log log ğ‘›)

James Cook
Unaffiliated
Toronto, Canada
falsifian@falsifian.org

Ian Mertz
University of Warwick
Coventry, United Kingdom
ian.mertz@warwick.ac.uk

ABSTRACT
The Tree Evaluation Problem (TreeEval) (Cook et al. 2009) is a cen-
tral candidate for separating polynomial time (P) from logarithmic
space (L) via composition. While space lower bounds of Î©(log2 ğ‘›)
are known for multiple restricted models, it was recently shown
by Cook and Mertz (2020) that TreeEval can be solved in space
ğ‘‚ (log2 ğ‘›/log log ğ‘›). Thus its status as a candidate hard problem for
L remains a mystery.

Our main result is to improve the space complexity of TreeEval
to ğ‘‚ (log ğ‘› Â· log log ğ‘›), thus greatly strengthening the case that Tree
Evaluation is in fact in L.

We show two consequences of these results. First, we show that
the KRW conjecture (Karchmer, Raz, and Wigderson 1995) implies
L âŠˆ NC1; this itself would have many implications, such as branch-
ing programs not being efficiently simulable by formulas. Our sec-
ond consequence is to increase our understanding of amortized
branching programs, also known as catalytic branching programs;
we show that every function ğ‘“ on ğ‘› bits can be computed by such
a program of length poly(ğ‘›) and width 2ğ‘‚ (ğ‘›) .

CCS CONCEPTS
â€¢ Theory of computation â†’ Complexity theory and logic;
Complexity classes.

KEYWORDS
Tree Evaluation Problem, Catalytic Computation, KRW Conjecture,
Branching Programs, Logspace, Composition Theorems

ACM Reference Format:
James Cook and Ian Mertz. 2024. Tree Evaluation Is in Space ğ‘‚ (log ğ‘› Â·
log log ğ‘›). In Proceedings of the 56th Annual ACM Symposium on Theory of
Computing (STOC â€™24), June 24â€“28, 2024, Vancouver, BC, Canada. ACM, New
York, NY, USA, 11 pages. https://doi.org/10.1145/3618260.3649664

1 INTRODUCTION
In complexity theory, many fundamental questions about time and
space remain open, including their relationship to one another.
We know that TIME(ğ‘¡) is sandwiched between SPACE(log ğ‘¡) and
SPACE(ğ‘¡/log ğ‘¡) [18], and both containments are widely considered
to be strict, but we have made little progress in proving this fact
for any ğ‘¡.

This work is licensed under a Creative Commons Attribution 4.0 Interna-
tional License.

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada
Â© 2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0383-6/24/06
https://doi.org/10.1145/3618260.3649664

1.1 Tree Evaluation and Composition
The Tree Evaluation Problem [10], henceforth TreeEval, has emerged
in recent years as a candidate for a function which is computable in
polynomial time (P = TIME(ğ‘›ğ‘‚ (1) )) but not in logarithmic space
(L = SPACE(ğ‘‚ (log ğ‘›))). This would resolve one of the two funda-
mental questions of time and space, showing that TIME(ğ‘¡) strictly
contains SPACE(log ğ‘¡) in at least one important setting.

TreeEval is parameterized by alphabet size ğ‘˜ and height â„. The
input is a rooted full binary tree of height â„, where each leaf is
given a value in [ğ‘˜] and each internal node is given a function from
[ğ‘˜] Ã— [ğ‘˜] to [ğ‘˜] represented explicitly as a table of ğ‘˜2 values. This
defines a natural bottom-up way to evaluate the tree: inductively
from the leaves, the value of a node is the value its function takes
when given the labels from its two children as input. The output of
a TreeEvalğ‘˜,â„ instance is the value of its root node.

A TreeEvalğ‘˜,â„ instance has size 2â„ Â· poly(ğ‘˜). The description
of the problem as given defines a polynomial time algorithm for
TreeEvalğ‘˜,â„: evaluate each node starting from the bottom and going
up, spending poly(ğ‘˜) time at each of the 2â„ nodes.

But what about space? Evaluating the output node requires us
to have the values of both of its children, which themselves are
obtained by computing their respective children, and so on. Now
imagine we have computed one of the children of the output node
and are moving to the other. This seems to require remembering the
value we have computed on one side, using log ğ‘˜ bits of memory,
and then on the other side computing a whole new TreeEvalğ‘˜,â„âˆ’1
instance, for which the same logic applies. This would inductively
give a space Î©(â„ log ğ‘˜) algorithm, while TreeEvalğ‘˜,â„ âˆˆ L would
mean giving an algorithm using only ğ‘‚ (â„ + log ğ‘˜) bits of memory.
Thus if our intuition is correct, this should be a separating exam-
ple for L and P. This led Cook, McKenzie, Wehr, Braverman, and San-
thanam [10] to define TreeEval and conjecture that Î©(â„ log ğ‘˜) space
is optimal. The conjecture was supported by multiple subsequent
works, which showed it holds in restricted, but also non-uniform,
settings such as thrifty algorithms [10]â€”a TreeEval-specific restric-
tion wherein algorithms are not allowed to read â€œunnecessaryâ€ input
bits, i.e. locations in the internal function tables that do not corre-
spond to the true inputs to the nodeâ€”and read-once [14] programs.
Later works extended both of these results to the non-deterministic
setting [20, 22].

This idea, known as composition or direct product theorems, is
not only studied in the context of space. The KRW conjecture of
Karchmer, Raz, and Wigderson [21] states that a similar logic holds
for formula depth, with the upshot being that TreeEval separates P
from the class of logarithmic depth formulas, known as NC1. Even
more so than space, the study of the KRW conjecture has yielded
many partial results (see e.g. [6, 13]) as well as encouraging useful
parallel lines of work such as lifting theorems [16, 26].

1268

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

James Cook and Ian Mertz

Thus the study of composition, and by extension TreeEval, is
a very fruitful and well-founded line of study, and it is of great
interest as to when this logic holds and when it fails.

1.2 Known Upper Bounds
Nevertheless, the consensus and central composition logic of the
space hardness of TreeEval has faced a challenge ever since its incep-
tion. Buhrman, Cleve, KouckÃ½, Loff, and Speelman [4] defined a new
model of space-bounded computation called catalytic computing in
order to challenge a crucial assumption in our lower bound strategy:
that the space used for remembering old values in the tree cannot
be useful for computing new values. Building on the work of Bar-
rington [1] and Ben-Or and Cleve [2], they show that the presence
of full memory can in fact assist in space-bounded computation in
a particular setting (unless L can compute log-depth threshold cir-
cuits, which would imply many things which are widely disbelieved,
e.g. NL = L).

The catalytic computing model later received attention from a
variety of works [3, 5, 12, 17], but while it was in part motivated to
challenge the conjecture of [10], it did not immediately lead to any
results about TreeEval. However, after a period of quiet on both
the upper and lower bound fronts, their objection was validated
by Cook and Mertz [7, 8], who showed that the Î©(â„ log ğ‘˜) argu-
ment does not hold. They proved that for any ğ‘˜ and â„, TreeEvalğ‘˜,â„
can be computed in space ğ‘‚ (â„ log ğ‘˜/log â„), which translates to an
algorithm using space at most ğ‘‚ (log2 ğ‘›/log log ğ‘›), shaving a loga-
rithmic factor off of the trivial algorithm using space ğ‘‚ (log2 ğ‘›).

This is a far cry from showing TreeEval âˆˆ L, but both the state-
ment and proof of the result undermine the central compositional
logic behind the approach of [10] to separate L from P.

1.3 Main Result
In this work we give an exponential improvement on the central
subroutine of [7, 8], which yields the following result.

Theorem 1. TreeEval can be computed in space ğ‘‚ (log ğ‘›Â·log log ğ‘›).

Compared to having only a logarithmic factor improvement
given by [7, 8], we are now only a logarithmic factor improvement
away from showing TreeEval âˆˆ L.

Our proof relies on a few fundamental properties of primitive
roots of unity over finite fields. After defining the main preliminaries
in Section 2, we go over these properties in Section 3, with our main
proof of Theorem 1 in Section 4. We then improve and generalize
our main subroutine, plus a discussion of the implications of these
sharper results, in Section 5.

As observed in [7, 8], our techniques avoid the restrictions for
which strong lower bounds are known. First, our algorithms avoid
the read-once restriction by repeatedly recomputing values through-
out the tree. Second, and perhaps more interesting, is that our algo-
rithm avoids the â€œthriftyâ€ restriction by relying on every value in
the table of any internal node, not only the one corresponding to
the true inputs.

1.4 Implications
Our improvement has immediate consequences outside of studying
space upper bounds on TreeEval. We discuss two such results in

this paper. All models and statements will be formally defined in
Sections 6 and 7 respectively.

1.4.1 The KRW Conjecture. First, we return to our brief discussion
of the KRW conjecture, which we recall implies that TreeEval âˆ‰
NC1. [7, 8] gave a space upper bound of ğ‘‚ (log2 ğ‘›/log log ğ‘›) for
TreeEval, asymptotically the same as the lower bound on formula
depth implied by the KRW conjecture; thus it was possible for the
KRW conjecture and L âŠ† NC1 to both be true. This is no longer
possible, as Theorem 1 makes these two hypotheses incompatible.

Theorem 2. If the KRW Conjecture holds, then L âŠˆ NC1.

We have not formally stated the KRW conjecture, and refrain
from doing so until Section 6; in fact one can define it in a variety
of ways, some stronger than others. We should note, however,
that Theorem 2 is quite robust with respect to choosing weaker
versions of the conjecture; any statement that implies TreeEval
requires formula depth ğœ” (log ğ‘›) is sufficient for Theorem 2. As we
show, the strongest (and most widely studied) version implies that L
requires formulas of depth Î©(log2 ğ‘›/log log ğ‘›), which nearly meets
the upper bound of ğ‘‚ (log2 ğ‘›) given by L âŠ† NC2.

There are multiple important takeaways. First, the KRW con-
jecture now implies a much sharper separation than P â‰  NC1.
Second, the KRW conjecture would give a superpolynomial size
separation between non-uniform formulas and uniform branching
programs; no superpolynomial separation is known even when
the uniformity, or lack thereof, is the same for both classes. Third,
proving formula lower bounds for TreeEval via KRW is formally
no easier than proving the same lower bounds for st-connectivity,
even in the undirected case. And fourth, and most philosophically,
continued belief in the KRW conjecture is a bet that the ability to
handle composition is the factor that separates space and formulas.

1.4.2 Catalytic Branching Programs. For our second result, we
consider the question of catalytic branching program size, or equiv-
alently amortized branching program size.

Branching programs are a syntactic model used to analyze space
in the non-uniform setting: we have a directed acyclic graph (DAG)
with one source node and two sinks, one for each potential output
of the function ğ‘“ ; computation proceeds by starting at the source
and, until we reach a sink labeled with the output ğ‘“ (ğ‘¥), at the
current internal node we query a bit of ğ‘¥ and proceed down some
adjacent edge according to the value read.

Drawing a connection to a model of space known as catalytic
computation, Girard, KouckÃ½, and McKenzie [15] introduced a
model known as ğ‘š-catalytic branching programs, which essentially
asks whether we can find smaller branching programs for comput-
ing an arbitrary function ğ‘“ if we only want to do so in an amortized
sense. We now consider a DAG with ğ‘š source nodes and 2ğ‘š sink
nodes, one for each (source, output) pair, and require that restricting
attention to any individual source gives us a branching program
for ğ‘“ in the usual sense. Nevertheless, we do not require internal
nodes to be disjoint; the question becomes whether such a program
can have size much less than ğ‘ ğ‘š, where ğ‘  is the size of the optimal
single-source branching program for ğ‘“ , and preferably with the
smallest value of ğ‘š, i.e. the least amount of amortization, possible.
Potechin [24] showed that, given enough amortization, this is
possible in the strongest way: every function ğ‘“ has ğ‘š-catalytic

1269

Tree Evaluation Is in Space ğ‘‚ (log ğ‘› Â· log log ğ‘›)

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

branching programs of size ğ‘‚ (ğ‘šğ‘›), regardless of the complexity of
ğ‘“ with respect to ordinary branching programs; the only catch is
that ğ‘š must be at least 22ğ‘›
. Reinterpreting and building on work of
Potechin [24] and an improvement by Robere and Zuiddam [27],
Cook and Mertz [9] used the TreeEval argument of [7, 8] in the
non-uniform setting to show that the amount of amortization can
be reduced to ğ‘š = 22ğœ–ğ‘›

for arbitrarily small constants ğœ– > 0.

By improving (a generalization of) the central subroutine of [7, 8]
in Theorem 1, we show that a slight sacrifice in the length gives a
near-optimal improvement in the amount of amortization.

Theorem 3. For every function ğ‘“ on ğ‘› bits, ğ‘“ has ğ‘š-catalytic

branching programs of the following size:

â€¢ size ğ‘‚ (ğ‘š Â· ğ‘›2+ğœ– ) with ğ‘š = ğ‘‚ (2(1+2/ğœ– )ğ‘›)
â€¢ size ğ‘‚ (ğ‘š Â· ğ‘›3/log2 ğ‘›) with ğ‘š = ğ‘‚ (2(2+ğ‘œ (1) )ğ‘›)
â€¢ size ğ‘‚ (ğ‘š Â· 22/ğœ–ğ‘›2) with ğ‘š = ğ‘‚ (2(2+ğœ– log ğ‘›)ğ‘›)

where ğœ– âˆˆ (0, 1/2] in the first and third points can be made arbitrarily
small.

Focusing on the first point, Theorem 3 can be interpreted as say-
ing that every function can be computed in amortized branching
program size just above ğ‘›2, where the total size of the program is
roughly 2ğ‘‚ (ğ‘›) . By the same counting argument as ordinary branch-
ing programs, we can hope for no better than amortized size ğ‘‚ (ğ‘›)â€”
as achieved by [9, 24, 27]â€”and total size ğ‘‚ (2ğ‘›/ğ‘›), meaning we are
not far from the tightest parameters possible.

2 PRELIMINARIES
In this work the base of logarithms will always be 2: log ğ‘¥ := log2 ğ‘¥.

2.1 Register Programs
We will use register programs as a convenient abstraction for describ-
ing space-bounded algorithms. Register programs were introduced
by Ben-Or and Cleve [2] based on work of Coppersmith and Gross-
man [11] and explored in a number of follow-up works [4, 7, 9].

Definition 1. A register program over ring R consists of a collection
of memory locations ğ‘… = {ğ‘…1 . . . ğ‘…ğ‘  }, called registers, each of which
can hold one element from R, and an ordered list of instructions in
the form of updates to some register ğ‘…ğ‘– based the current values of
the registers and an input ğ‘¥ âˆˆ {0, 1}ğ‘›.

We are primarily interested in register programs which can be

simulated by space-bounded algorithms:
Definition 2. A family of register programs ğ‘ƒ = {ğ‘ƒğ‘› }ğ‘›âˆˆN is space
ğ‘ (ğ‘›) uniform if there is an algorithm using space ğ‘ (ğ‘›) which, given
(ğ‘¡, ğ‘¥) and access to an array of registers, performs the ğ‘¡-th instruc-
tion of ğ‘ƒğ‘› on input ğ‘¥ âˆˆ {0, 1}ğ‘›.

Although it is common to restrict register programs to a small
vocabulary of instructions, in this work we make no restriction
beyond Definition 2. So, our programs may include any instruction

ğ‘…ğ‘– â† ğ‘…ğ‘– + ğ‘”(ğ‘¥1 . . . ğ‘¥ğ‘›, ğ‘…1 . . . ğ‘…ğ‘  )

as long as ğ‘” can be computed in space ğ‘ (ğ‘›).

Following [4], rather than directly writing their output to a reg-
ister, our programs will add their output to a register while leaving
other registers unchanged, a process we call clean computation.
This will be useful for making our algorithms space-efficient.

Definition 3. Let R be a ring and let ğ‘“ be a function whose output
can be represented in R. A register program over R with ğ‘  registers
cleanly computes ğ‘“ into a register ğ‘…ğ‘œ if for all possible ğ‘¥1 . . . ğ‘¥ğ‘› âˆˆ
{0, 1}ğ‘› and ğœ1 . . . ğœğ‘  âˆˆ R, if the program is run after initializing each
register ğ‘…ğ‘– = ğœğ‘– , then at the end of the execution

ğ‘…ğ‘œ = ğœğ‘œ + ğ‘“ (ğ‘¥1 . . . ğ‘¥ğ‘›)
ğ‘…ğ‘– = ğœğ‘– âˆ€ğ‘– â‰  ğ‘œ

We will often want to undo the effect of a register program:

Definition 4.
If ğ‘ƒ is a register program that cleanly computes
ğ‘“ (ğ‘¥1 . . . ğ‘¥ğ‘›), an inverse to ğ‘ƒ is any program ğ‘ƒ âˆ’1 which computes
âˆ’ğ‘“ (ğ‘¥1 . . . ğ‘¥ğ‘›).

For example, one way to construct ğ‘ƒ âˆ’1 is:
1: ğ‘…ğ‘œ â† âˆ’ğ‘…ğ‘œ
2: ğ‘ƒ
3: ğ‘…ğ‘œ â† âˆ’ğ‘…ğ‘œ

Notice that running ğ‘ƒ followed by ğ‘ƒ âˆ’1, or vice versa, leaves every
register including ğ‘…ğ‘œ unchanged.

We justify our use of uniform register programs and clean com-
putation to describe space-bounded algorithms with the following
connection:

Proposition 1. For ğ‘› âˆˆ N, let ğ‘ := ğ‘ (ğ‘›), ğ‘  := ğ‘  (ğ‘›), ğ‘¡ := ğ‘¡ (ğ‘›) âˆˆ N,
and let R := Rğ‘› be a ring. Let ğ‘“ := ğ‘“ğ‘› be a Boolean function on ğ‘›
variables, and let ğ‘ƒ := ğ‘ƒğ‘› be a space ğ‘ uniform register program, which
ğ‘  registers over R and which has ğ‘¡ instructions in total, that cleanly
computes ğ‘“ . Then ğ‘“ can be computed in space ğ‘‚ (ğ‘ + ğ‘  log |R| + log ğ‘¡).

2.2 Finite Fields
In our programs, the ring R will always be a finite field. For a prime
number ğ‘ and positive integer ğ‘, we define Fğ‘ğ‘ to be the unique
(up to isomorphism) field with ğ‘ğ‘ elements.

Proposition 2. Every element ğ‘¥ âˆˆ Fğ‘ğ‘ can be represented by a
string of length ğ‘‚ (log |Fğ‘ğ‘ |) = ğ‘‚ (ğ‘ log ğ‘), and given any two such
strings representing ğ‘¥, ğ‘¦ âˆˆ Fğ‘ğ‘ , the representation of ğ‘¥ + ğ‘¦, ğ‘¥ Ã— ğ‘¦, and
ğ‘¥/ğ‘¦ over Fğ‘ğ‘ can be computed in space ğ‘‚ (log |Fğ‘ğ‘ |) = ğ‘‚ (ğ‘ log ğ‘).

Proof. Fix an irreducible degree-ğ‘ polynomial ğ‘“ (ğ‘¥) âˆˆ Fğ‘ [ğ‘¥],
so that Fğ‘ğ‘ is isomorphic to Fğ‘ [ğ‘¥]/(ğ‘“ (ğ‘¥)). Then each field element
is represented by a polynomial of degree less than ğ‘, which we can
store as an ğ‘-tuple of coefficients in Fğ‘ . It is then straightforward
to add, multiply and divide field elements in ğ‘‚ (ğ‘ log ğ‘) space. All
this requires finding a suitable ğ‘“ (ğ‘¥) to begin with; this can also be
â–¡
done in ğ‘‚ (ğ‘ log ğ‘) space by exhaustive search.

We will sometimes need a smaller field inside a larger finite field:

Proposition 3. For every prime number ğ‘ and positive integers ğ‘, ğ‘,
the field Fğ‘ğ‘ is isomorphic to a subfield of Fğ‘ğ‘ğ‘ .

Again it is computationally possible to find representations of
Fğ‘ğ‘ and Fğ‘ğ‘ğ‘ that agree1; thus we will treat Fğ‘ğ‘ as a subset of Fğ‘ğ‘ğ‘
when performing computations.

1For example, one way to do that is to first find an irreducible polynomial ğ‘“ (ğ‘¥ ) âˆˆ
Fğ‘ [ğ‘¥ ] such that Fğ‘ğ‘ is isomorphic to Fğ‘ [ğ‘¥ ]/(ğ‘“ (ğ‘¥ ) ), and then find ğ‘” (ğ‘¦) âˆˆ Fğ‘ğ‘ [ğ‘¦ ]
such that ğ¹ğ‘ğ‘ğ‘ is isomorphic to Fğ‘ğ‘ [ğ‘¦ ]/(ğ‘” (ğ‘¦) ), with elements of Fğ‘ being repre-
sented as constant (degree-0) polynomials in ğ¹ğ‘ğ‘ [ğ‘¦ ].

1270

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

James Cook and Ian Mertz

3 ROOTS OF UNITY
Our work will use primitive roots of unity, and so we introduce them
and some of their properties before describing our algorithms. All
definitions and statements appearing in this section are standard
and have been used many times before in the literature, but will be
crucial to the proof of our main results.

Definition 5. An element ğœ” of a field K is a root of unity of order
ğ‘š if ğœ”ğ‘š = 1. It is a primitive root of unity if additionally ğœ”ğ‘˜ â‰  1 for
every integer 0 < ğ‘˜ < ğ‘š.

Our algorithm relies on some properties of primitive roots of
unityâ€”naturally, first we require that they exist, with the order we
need:

Proposition 4. Every finite field K has a primitive root of unity of
order |K | âˆ’ 1.

This follows from the fact that the multiplicative group K Ã— of a
finite field is always a cycle. For K = Fğ‘ğ‘ , such a primitive root of
unity can be found in ğ‘‚ (ğ‘ log ğ‘) space through exhaustive search.
We will use, and for completeness prove, a generalization of the

fact that

ğ‘š
ğ‘—=1 ğœ” ğ‘— = 0.

Proposition 5. Let K be a finite field, and let ğœ” be a primitive root
of unity of order ğ‘š in K. Then for all 0 < ğ‘ < ğ‘š,

Ã

ğœ” ğ‘—ğ‘ = 0

ğ‘š

Ã•ğ‘—=1

Proof. Let ğ‘  =

ğœ” ğ‘—ğ‘ . Then

ğ‘š

Ã•ğ‘—=1

ğœ”ğ‘ğ‘  =

ğ‘š+1

Ã•ğ‘—=2

ğœ” ğ‘—ğ‘ = ğ‘  + ğœ” (ğ‘š+1)ğ‘ âˆ’ ğœ”ğ‘ = ğ‘  + ğœ”ğ‘ (ğœ”ğ‘šğ‘ âˆ’ 1) = ğ‘ 

since ğœ”ğ‘šğ‘ = 1ğ‘ = 1. So either ğœ”ğ‘ = 1 or ğ‘  = 0, but the former is
ruled out because ğœ” is a primitive root of unity and 0 < ğ‘ < ğ‘š. â–¡

Corollary 6. Let K be a finite field, let ğ‘š = |K | âˆ’ 1, and let ğœ” be a
primitive root of unity of order ğ‘š in K. Then for all 0 â‰¤ ğ‘ < ğ‘š,

ğ‘š

ğœ” ğ‘—ğ‘ = âˆ’1 Â· [ğ‘ = 0]

Ã•ğ‘—=1

where [ğ‘ = 0] is the indicator function which takes value 1 if ğ‘ = 0
and 0 otherwise.

Proof. The case of ğ‘ â‰  0 is handled by Proposition 5. For ğ‘ = 0

we have that over K,

ğ‘š

ğœ” ğ‘—0 =

ğ‘š

1 = ğ‘š = âˆ’1

where the last equality holds because ğ‘š = âˆ’1 in K.

Ã•ğ‘—=1

Ã•ğ‘—=1

Theorem 4. Any TreeEvalğ‘˜,â„ instance can be computed in space

ğ‘‚ ((â„ + log ğ‘˜) Â· log log ğ‘˜).

We will build our algorithm from the ground up, first showing

how to compute each individual node.

Lemma 7. Let K be a finite field, let ğ‘š = |K | âˆ’ 1, and let ğœ” be a
primitive root of unity of order ğ‘š in K. Let ğ‘‘ < ğ‘š, and let ğœğ‘–, ğ‘¥ğ‘– be
elements of K for ğ‘– âˆˆ [ğ‘‘]. Then

ğ‘š

ğ‘‘

Ã•ğ‘—=1

Ã–ğ‘–=1

(ğœ” ğ‘—ğœğ‘– + ğ‘¥ğ‘– ) = âˆ’1 Â·

ğ‘¥ğ‘–

ğ‘‘

Ã–ğ‘–=1

Before going into the proof of Lemma 7, we should stress why it
is useful. Our overall goal is to compute the function ğ‘“ğ‘¢ at node ğ‘¢
in our TreeEval instance while only using clean access to its inputs,
i.e. we only assume we can add some input bit ğ‘¥ğ‘– to whatever ğœğ‘–
already exists in the target register ğ‘…ğ‘– . Thus, when operating over
registers ğ‘…ğ‘– , we need to remove the contributions of the ğœğ‘– values
themselves when computing ğ‘“ğ‘¢ . Lemma 7 accomplishes just this
for the AND function over ğ‘‘ inputs, albeit using ğœğ‘– multiplied by ğ‘š
different coefficients. After proving this lemma, we will move to
the actual question, which is to compute an arbitrary ğ‘“ğ‘¢ .

Proof. For a fixed ğ‘—, expanding the product on the left hand

side gives

ğ‘‘

Ã–ğ‘–=1

(ğœ” ğ‘—ğœğ‘– + ğ‘¥ğ‘– ) =

ğœ” ğ‘—ğœğ‘–

!

Ã•ğ‘† âŠ† [ğ‘‘ ]

Ã–ğ‘– âˆˆğ‘†

ğ‘¥ğ‘–

Ã–ğ‘– âˆˆ [ğ‘‘ ]\ğ‘†
Â©

Âª
Â®
ğ‘¥ğ‘–
Â¬
Ã–ğ‘– âˆˆ [ğ‘‘ ]\ğ‘†
Â©

Âª
Â®
Â¬

=

ğœ” ğ‘— |ğ‘† |

Ã•ğ‘† âŠ† [ğ‘‘ ]

ğœğ‘–
Â«

!

Ã–ğ‘– âˆˆğ‘†

Â«

(ğœ” ğ‘—ğœğ‘– + ğ‘¥ğ‘– )

If we sum over all ğ‘— and switch the sums we get

ğ‘š

ğ‘‘

Ã–ğ‘–=1

Ã•ğ‘—=1
ğ‘š

=

=

Ã•ğ‘—=1 Ã•ğ‘† âŠ† [ğ‘‘ ]
ğ‘š

ğœ” ğ‘— |ğ‘† |

ğœ” ğ‘— |ğ‘† |

ğœğ‘–

!

Ã–ğ‘– âˆˆğ‘†

Ã–ğ‘– âˆˆ [ğ‘‘ ]\ğ‘†
Â©

ğ‘¥ğ‘–

Âª
Â®
ğ‘¥ğ‘–
Â¬

ğœğ‘–
Â«
!

Ã–ğ‘– âˆˆğ‘†

Âª
Â®
Â¬

Ã–ğ‘– âˆˆ [ğ‘‘ ]\ğ‘†
Â©

Â«

Âª
Â®
Â¬

Â«
ğ‘š

Ã•ğ‘—=1

ğœ” ğ‘— Â· |ğ‘† | = âˆ’1 Â· [|ğ‘† | = 0]

Ã•ğ‘† âŠ† [ğ‘‘ ]

Ã•ğ‘—=1

Â©

By Corollary 6 we have

â–¡

and thus the outer sum simplifies to the |ğ‘† | = 0 term, which only
has ğ‘† = âˆ…:

4 TREE EVALUATION IN LOW SPACE
We now move on to the main goal of our paper, which is to prove
Theorem 1. The following is our main result for TreeEvalğ‘˜,â„, stated
in terms of the two main parameters. It implies Theorem 1 for any
setting of ğ‘˜ and â„, and is stronger as ğ‘˜ gets smaller with respect to
the total input size.

1271

ğ‘š

ğ‘‘

(ğœ” ğ‘—ğœğ‘– + ğ‘¥ğ‘– ) = âˆ’1 Â·

ğœğ‘–

ğ‘¥ğ‘–

= âˆ’1 Â·

ğ‘¥ğ‘– â–¡

Ã–ğ‘–=1

Ã•ğ‘—=1
Thus the next step is to move from individual products to poly-
nomials. This is accomplished by a simple corollary of Lemma 7.

Ã–ğ‘– âˆˆ [ğ‘‘ ]\âˆ…
Â©

Ã–ğ‘– âˆˆ [ğ‘‘ ]

Ã–ğ‘– âˆˆâˆ…

Âª
Â®
Â¬

Â«

!

Tree Evaluation Is in Space ğ‘‚ (log ğ‘› Â· log log ğ‘›)

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

Lemma 8. Let K be a finite field, let ğ‘š = |K | âˆ’ 1, and let ğœ” be
a primitive root of unity of order ğ‘š in K. Let ğ‘ : Kğ‘› â†’ K be a
degree-ğ‘‘ polynomial for some ğ‘‘ < ğ‘š, and let ğœğ‘–, ğ‘¥ğ‘– be elements of K
for ğ‘– âˆˆ [ğ‘›]. Then

âˆ’1 Â· ğ‘ (ğœ” ğ‘—ğœ1 + ğ‘¥1, . . . , ğœ” ğ‘—ğœğ‘› + ğ‘¥ğ‘›) = ğ‘ (ğ‘¥1 . . . ğ‘¥ğ‘›)

ğ‘š

Ã•ğ‘—=1

Proof. Writing ğ‘ as a sum of monomials we have

ğ‘ (ğ‘¦1 . . . ğ‘¦ğ‘›) =

ğ‘ğ¼

ğ‘¦ğ‘–

Ã•ğ¼ âŠ† [ğ‘›]
|ğ¼ | â‰¤ğ‘‘

Ã–ğ‘– âˆˆğ¼

for some coefficients ğ‘ğ¼ âˆˆ K and formal variables ğ‘¦1 . . . ğ‘¦ğ‘›. Then by
substituting ğœ” ğ‘—ğœğ‘– + ğ‘¥ğ‘– for each ğ‘¦ğ‘– and summing over all ğ‘—, Lemma 7
gives

ğ‘¦ğ‘– âˆˆ {0, 1}, and similarly replacing [ğ‘§ = ğ›¾] with ğ‘’ (ğ‘§, ğ›¾). This gives
the polynomial

[ğ‘“ğ‘¢ (ğ›½, ğ›¾) = ğ›¼]ğ‘’ (ğ‘¦, ğ›½)ğ‘’ (ğ‘§, ğ›¾)

(1)

Ã•ğ›¼,ğ›½,ğ›¾ âˆˆ [ğ‘˜ ]3
ğ›¼ğ‘– =1

We call this ğ‘ğ‘¢,ğ‘– (ğ‘¦, ğ‘§) and note that it is multilinear and thus has
degree at most 2âŒˆlog ğ‘˜âŒ‰.

Now given the conversion to polynomials ğ‘ğ‘¢,ğ‘– , we use Lemma 8
to compute the values ğ‘ğ‘¢,ğ‘– (ğ‘¦, ğ‘§) for inputs ğ‘¦, ğ‘§ coming from ğ‘ƒâ„“ and
ğ‘ƒğ‘Ÿ respectively. Let ğœ” be a primitive root of unity of order ğ‘š in K,
and for all ğ‘ âˆˆ {â„“, ğ‘Ÿ } and ğ‘– âˆˆ [âŒˆlog ğ‘˜âŒ‰], let ğœğ‘,ğ‘– be the initial value of
ğ‘…ğ‘,ğ‘– . Our goal will be to compute

ğ‘…ğ‘¢,ğ‘– â† ğ‘…ğ‘¢,ğ‘– +

ğ‘š

Ã•ğ‘—=1

âˆ’1 Â· ğ‘ğ‘¢,ğ‘– (ğœ” ğ‘—ğœâ„“ + ğ‘¦, ğœğ‘Ÿ + ğ‘§)

âˆ€ğ‘– âˆˆ [âŒˆlog ğ‘˜âŒ‰]

where ğœ” ğ‘—ğœâ„“ + ğ‘¦ and ğœ” ğ‘—ğœğ‘Ÿ + ğ‘§ are shorthand for âŒˆlog ğ‘˜âŒ‰ values each.
We do so using the following program ğ‘ƒğ‘¢ :

1: for ğ‘— = 1 . . . ğ‘š do
2:

for ğ‘ âˆˆ {â„“, ğ‘Ÿ }, ğ‘– = 1 . . . âŒˆlog ğ‘˜âŒ‰ do

âˆ’1 Â· ğ‘ (ğœ” ğ‘—ğœ1 + ğ‘¥1, . . . , ğœ” ğ‘—ğœğ‘› + ğ‘¥ğ‘›)

âˆ’1 Â·

ğ‘ğ¼

(ğœ” ğ‘—ğœğ‘– + ğ‘¥ğ‘– )

ğ‘š

Ã•ğ‘—=1
ğ‘š

Ã•ğ‘—=1

=

=

=

Ã•ğ¼ âŠ† [ğ‘›]
|ğ¼ | â‰¤ğ‘‘

Ã–ğ‘– âˆˆğ¼

ğ‘š

ğ‘ğ¼ Â·

âˆ’1 Â·

Ã•ğ¼ âŠ† [ğ‘›]
|ğ¼ | â‰¤ğ‘‘

Â©

Ã•ğ‘—=1 Ã–ğ‘– âˆˆğ¼

ğ‘ğ¼

ğ‘¥ğ‘–

Â«
Ã–ğ‘– âˆˆğ¼

Ã•ğ¼ âŠ† [ğ‘›]
|ğ¼ | â‰¤ğ‘‘

(ğœ” ğ‘—ğœğ‘– + ğ‘¥ğ‘– )

Âª
Â®
Â¬

3:

4:

5:

6:

7:

8:

9:

ğ‘…ğ‘,ğ‘– â† ğœ” ğ‘— Â· ğ‘…ğ‘,ğ‘–

ğ‘ƒâ„“, ğ‘ƒğ‘Ÿ
for ğ‘– = 1 . . . âŒˆlog ğ‘˜âŒ‰ do

ğ‘…ğ‘¢,ğ‘– â† ğ‘…ğ‘¢,ğ‘– âˆ’ ğ‘ğ‘¢,ğ‘– (ğ‘…â„“, ğ‘…ğ‘Ÿ )
, ğ‘ƒ âˆ’1
ğ‘Ÿ

ğ‘ƒ âˆ’1
â„“
for ğ‘ âˆˆ {â„“, ğ‘Ÿ }, ğ‘– = 1 . . . âŒˆlog ğ‘˜âŒ‰ do

ğ‘…ğ‘,ğ‘– â† ğœ” âˆ’ ğ‘— Â· ğ‘…ğ‘,ğ‘–

and the last line is ğ‘ (ğ‘¥1 . . . ğ‘¥ğ‘›) by definition.

â–¡

Finally, we show how to use Lemma 8 in a register program to
compute our polynomial ğ‘“ğ‘¢ in the way we described above, given
an appropriate choice of K.

Lemma 9. Let K be a finite field such that ğ‘š := |K | âˆ’ 1 > 2âŒˆlog ğ‘˜âŒ‰.
Let ğ‘ƒâ„“, ğ‘ƒğ‘Ÿ be register programs which cleanly compute values ğ‘£â„“, ğ‘£ğ‘Ÿ âˆˆ
{0, 1}âŒˆlog ğ‘˜ âŒ‰ into registers ğ‘…â„“, ğ‘…ğ‘Ÿ âˆˆ K âŒˆlog ğ‘˜ âŒ‰ , respectively, and let
ğ‘ƒ âˆ’1
be their inverses. Let ğ‘“ğ‘¢ : {0, 1}2âŒˆlog ğ‘˜ âŒ‰ â†’ {0, 1}âŒˆlog ğ‘˜ âŒ‰ be
â„“
the function at node ğ‘¢ in our TreeEvalğ‘˜,â„ instance.

, ğ‘ƒ âˆ’1
ğ‘Ÿ

Then there exists a register program ğ‘ƒğ‘¢ which cleanly computes
ğ‘“ğ‘¢ (ğ‘£â„“, ğ‘£ğ‘Ÿ ) âˆˆ {0, 1}âŒˆlog ğ‘˜ âŒ‰ into registers ğ‘…ğ‘¢ âˆˆ K âŒˆlog ğ‘˜ âŒ‰ , as well as an
inverse program ğ‘ƒ âˆ’1
ğ‘¢ make ğ‘š recursive calls each
to ğ‘ƒâ„“ , ğ‘ƒğ‘Ÿ , ğ‘ƒ âˆ’1
, and use 5ğ‘šâŒˆlog ğ‘˜âŒ‰ other basic instructions.
ğ‘Ÿ

ğ‘¢ . Both ğ‘ƒğ‘¢ and ğ‘ƒ âˆ’1

, and ğ‘ƒ âˆ’1

â„“

We use for . . . do as shorthand for concatenating several copies
of a block of instructions with varying parameters. So, for example,
lines 2â€“3 describe a sequence of 2âŒˆlog ğ‘˜âŒ‰ register program instruc-
tions with a different pair (ğ‘, ğ‘–) associated to each, and the block
from lines 2â€“9 is repeated ğ‘š times with different values of ğ‘—. Lines
4 and 7 are shorthand for inserting complete copies of the register
programs ğ‘ƒâ„“, ğ‘ƒğ‘Ÿ , ğ‘ƒ âˆ’1

.

, ğ‘ƒ âˆ’1
ğ‘Ÿ

On the other hand, each of lines 3, 6, and 9 represents a single
instruction (to be repeated several times due to the surrounding
for loops), even though computing line 6 involves poly(ğ‘˜) field
arithmetic operations. Recall from Section 2 that a single instruction
of a space ğ‘ uniform register program may compute any function
computable in space ğ‘. See the end of the proof of Theorem 4 for
an account of the space ğ‘ required for these instructions.

â„“

To make the inverse program ğ‘ƒ âˆ’1

ğ‘¢ , replace the âˆ’ on line 6 with

+.

Proof. Our goal will be to use Lemma 8 in order to compute the
output of ğ‘“ğ‘¢ using only clean access to the values of its children.
In order to do this, we first need to convert ğ‘“ğ‘¢ into a tuple of
polynomials. We can write the ğ‘–-th bit of ğ‘“ğ‘¢ as:

(ğ‘“ğ‘¢ (ğ‘¦, ğ‘§))ğ‘– =

[ğ›¼ğ‘– = 1] [ğ‘“ğ‘¢ (ğ›½, ğ›¾) = ğ›¼] [ğ‘¦ = ğ›½] [ğ‘§ = ğ›¾]

Ã•ğ›¼,ğ›½,ğ›¾ âˆˆ [ğ‘˜ ]3

We now analyze the correctness of the program. At the start of
an iteration of the loop, we have ğ‘…ğ‘,ğ‘– = ğœğ‘,ğ‘– , and since lines 7â€“9 are
the inverse of lines 3â€“4, this invariant is maintained at the end of
the iteration; this additionally implies that ğ‘…ğ‘,ğ‘– = ğœğ‘,ğ‘– at the end of
the program as required. Going into lines 5 and 6, we have that

ğ‘…ğ‘,ğ‘– = ğœ” ğ‘—ğœğ‘,ğ‘– + ğ‘£ğ‘,ğ‘–

âˆ€ğ‘ âˆˆ {â„“, ğ‘Ÿ }, ğ‘– âˆˆ [âŒˆlog ğ‘˜âŒ‰]

We will turn this into a polynomial whose 2âŒˆlog ğ‘˜âŒ‰ variables are the
bits of ğ‘¦ and ğ‘§ by replacing [ğ‘¦ = ğ›½] with the polynomial ğ‘’ (ğ‘¦, ğ›½) =
(1 âˆ’ ğ‘¦ğ‘– + (2ğ‘¦ğ‘– âˆ’ 1)ğ›½ğ‘– ), which equals [ğ‘¦ = ğ›½] when all

âŒˆlog ğ‘˜ âŒ‰
ğ‘–=1

where ğ‘š is larger than the degree of each ğ‘ğ‘¢,ğ‘– , and so correctness
follows from Lemma 8 and the fact that ğ‘ğ‘¢,ğ‘– (ğ‘¦, ğ‘§) = (ğ‘“ğ‘¢ (ğ‘¦, ğ‘§))ğ‘– when
â–¡
all ğ‘¦ğ‘–, ğ‘§ğ‘– âˆˆ {0, 1}.

Ã

1272

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

James Cook and Ian Mertz

The above program can be made more efficient, as we will show
in Lemma 10 in Section 5, but even as stated Lemma 9 is sufficient
to serve as our main TreeEval subroutine.

Proof of Theorem 4. We will show that our TreeEvalğ‘˜,â„ in-
stance can be cleanly computed by a register program of length
at most (4|K |)â„ âŒˆlog ğ‘˜âŒ‰ and using 3âŒˆlog ğ‘˜âŒ‰ registers over K, and
that the register program is space ğ‘‚ (â„ log |K | + log ğ‘˜) uniform. By
Proposition 1, our space usage will ultimately be

ğ‘‚ (â„ log |K | + log ğ‘˜ + log ğ‘˜ Â· log |K |)

which is ğ‘‚ ((â„ + log ğ‘˜) log log ğ‘˜) if we choose K to be a field of size
ğ‘‚ (log ğ‘˜).

We build our register program by induction, showing that for ev-
ery node ğ‘¢ of height ğ‘‘ â‰¤ â„ such a program of length (4|K |)ğ‘‘ âŒˆlog ğ‘˜âŒ‰
computing ğ‘“ğ‘¢ exists. For ğ‘‘ = 0, i.e. a leaf node, both ğ‘ƒğ‘¢ and ğ‘ƒ âˆ’1
ğ‘¢ can
be computed by reading the nodeâ€™s value directly from the input,
which gives register programs of length

âŒˆlog ğ‘˜âŒ‰ = (4 Â· |K |)0 âŒˆlog ğ‘˜âŒ‰

since one instruction is needed for each of the âŒˆlog ğ‘˜âŒ‰ output regis-
ters.

Now for a node ğ‘¢ at height ğ‘‘ + 1, we will inductively assume
we have register programs ğ‘ƒâ„“, ğ‘ƒğ‘Ÿ for the children â„“, ğ‘Ÿ of ğ‘¢, each of
length (4 Â· |K |)ğ‘‘ âŒˆlog ğ‘˜âŒ‰ and which use 3âŒˆlog ğ‘˜âŒ‰ registers. We will
organize our registers into tuples ğ‘…â„“, ğ‘…ğ‘Ÿ , ğ‘…ğ‘¢ , where ğ‘ƒâ„“ will compute
ğ‘“â„“ into ğ‘…â„“ and ğ‘ƒğ‘Ÿ will compute ğ‘“ğ‘Ÿ into ğ‘…ğ‘Ÿ ; our goal then will be to
compute ğ‘“ğ‘¢ into ğ‘ƒğ‘¢ .

Assuming |K | âˆ’1 > 2âŒˆlog ğ‘˜âŒ‰, we apply Lemma 9 to ğ‘¢, inductively

giving us a program of length

(|K | âˆ’ 1) Â· [4 Â· (4 Â· |K |)ğ‘‘ âŒˆlog ğ‘˜âŒ‰ + 5âŒˆlog ğ‘˜âŒ‰] â‰¤ (4 Â· |K |)ğ‘‘+1 âŒˆlog ğ‘˜âŒ‰

This completes the recursion. We choose

K = F2âŒˆlog(2âŒˆlog ğ‘˜âŒ‰+2) âŒ‰
which satisfies our two conditions2: 1) K has size ğ‘‚ (log ğ‘˜), ensuring
efficiency; and 2) |K | âˆ’ 1 > 2âŒˆlog ğ‘˜âŒ‰, ensuring correctness.

It remains only to show that our register program is space
ğ‘‚ (â„ log |K | + log ğ‘˜) uniform. Recall this means (Definition 2) that
on input (ğ‘¡, ğ‘¥), we can perform the ğ‘¡-th step of the program in space
ğ‘‚ (â„ log |K | + log ğ‘˜).

The first task is to figure out what the ğ‘¡-th instruction is. The reg-
ister program given by Lemma 9 has an outer loop with ğ‘š = |K | âˆ’ 1
iterations, so the first step is to figure out which iteration the instruc-
tion lies withinâ€”i.e. the value of ğ‘—â€”and which instruction number
ğ‘¡ â€² it is within that iteration: ğ‘¡ = ğ‘‡ ğ‘— + ğ‘¡ â€² where ğ‘‡ is the length of
each iteration. Then based on ğ‘¡ â€² we must determine where within
the iteration the instruction lies; for example, if ğ‘¡ â€² â‰¤ 2âŒˆlog ğ‘˜âŒ‰,
itâ€™s line 3, with the values of ğ‘ âˆˆ {â„“, ğ‘Ÿ } and ğ‘– âˆˆ [âŒˆlog ğ‘˜âŒ‰] deter-
mined by ğ‘¡ â€². If the instruction lies within one of the recursive calls
to ğ‘ƒâ„“, ğ‘ƒğ‘Ÿ , ğ‘ƒ âˆ’1
, then we must figure out where within that re-
cursive call the instruction lies, and so on. This can all be done

, ğ‘ƒ âˆ’1
ğ‘Ÿ

â„“

2Any other K satisfying these constraints would work: for example, Fğ‘ where ğ‘ is a
prime number between 2âŒˆlog ğ‘˜ âŒ‰ + 2 and 4âŒˆlog ğ‘˜ âŒ‰ + 4.

1273

with simple arithmetic; since the length of the program is at most
(4|K |)â„ âŒˆlog ğ‘˜âŒ‰, this requires space ğ‘‚ (â„ log |K | + log ğ‘˜).3

Finally the instruction itself must be performed. Lines 3 and 9 can
be performed in space ğ‘‚ (log ğ‘˜ + log |K |), because field operations
can be performed in space ğ‘‚ (log |K |) (Proposition 2), and log ğ‘— â‰¤
log ğ‘˜ bits suffice to create a loop to compute ğœ” ğ‘— .

It remains to compute line 6. We do this using the definition of
ğ‘ğ‘¢,ğ‘– as stated in Equation 1. Taking the outer sum means storing
three values in [ğ‘˜], for 3âŒˆlog ğ‘˜âŒ‰ bits in total, plus ğ‘‚ (log |K |) bits to
keep track of the total thus far. Each coefficient [ğ‘“ğ‘¢ (ğ›½, ğ›¾) = ğ›¼] is
directly given in the input to TreeEval and can be addressed using
ğ‘‚ (log ğ‘›) = ğ‘‚ (â„ + log ğ‘˜) bits. We can compute the product one value
at a time, using one counter for the index and one field element for
the product thus far, giving âŒˆlog ğ‘˜âŒ‰ and ğ‘‚ (log |K |) bits, respectively.
Lastly, by taking into account the ğ‘‚ (log |K |) space of computing
operations over K (again by Proposition 2), the total space usage is
â–¡
at most ğ‘‚ (log ğ‘˜ + â„ + log |K |).

5 IMPROVEMENTS AND GENERALIZATIONS
For the rest of this paper we will adapt the techniques used to
other questions in complexity theory. To do so, we will first state
Lemma 9, which is our main subroutine, in a more general and
efficient form.

Lemma 10. Let K be a finite field with a subfield F âŠ† K, let
ğ‘“ : F ğ‘ â†’ F ğ‘ be a function where ğ‘(|F | âˆ’ 1) < |K | âˆ’ 1, and let
ğ‘ƒğ‘” be a register program with at least ğ‘ + ğ‘ registers over K which
cleanly computes a value ğ‘” âˆˆ F ğ‘ into registers ğ‘…1 . . . ğ‘…ğ‘.

Then there exists a register program ğ‘ƒğ‘“ which cleanly computes
ğ‘“ (ğ‘”) into registers ğ‘…ğ‘+1 . . . ğ‘…ğ‘+ğ‘ . The length of ğ‘ƒğ‘“ is (|K | âˆ’1)(ğ‘¡ (ğ‘ƒğ‘”) +
2ğ‘ + ğ‘) where ğ‘¡ (ğ‘ƒğ‘”) is the length of ğ‘ƒğ‘”, and ğ‘ƒğ‘“ uses the same set of
registers as ğ‘ƒğ‘”.

To see Lemma 9 as a special case4 of Lemma 10, take F = F2,
ğ‘ = 2âŒˆlog ğ‘˜âŒ‰ and ğ‘ = âŒˆlog ğ‘˜âŒ‰, and let ğ‘” be the concatenation of the
values ğ‘£â„“, ğ‘£ğ‘Ÿ , with ğ‘ƒğ‘” calling ğ‘ƒâ„“ then ğ‘ƒğ‘Ÿ . Lemma 10 saves some time
by avoiding the need to call the inverse program ğ‘ƒ âˆ’1
ğ‘” .

The proof is essentially that of Lemma 9, and will appear at the
end of this section. First, we will use this statement to obtain our
results in the next two sections.

To get a sense of the utility of this generalization, as a first
application we show how to reduce the space used by our TreeEval
algorithm for storing registers. Our algorithm currently uses space
ğ‘‚ (log ğ‘› Â· log log ğ‘›) both to keep track of time and to store the
memory in the registers. We can improve this to logspace for one
of these two aspects, namely the register memory.

Theorem 5. Any TreeEvalğ‘˜,â„ instance can be computed in space

ğ‘‚ (â„ log log ğ‘˜ + log ğ‘˜).

One consequence of this theorem is that only TreeEvalğ‘˜,â„ in-
stances of essentially maximal height can possibly be used to prove
space lower bounds.

3Put another way, tracking where we are within the recursive calls requires up to â„
stack frames, each storing a number ğ‘— âˆˆ [ | K | âˆ’ 1], plus ğ‘‚ (log ğ‘˜ ) bits to understand
which iteration of the loops on lines 2, 5, and 8 we are on if we are not inside a recursive
call, for a total of ğ‘‚ (â„ log | K | + log ğ‘˜ ) space.
4Strictly speaking, it is not a special case, since Lemma 9 encodes values as bit strings
(meaning F = F2 in terms of Lemma 10) but does not require F2 to be a subfield of K.

Tree Evaluation Is in Space ğ‘‚ (log ğ‘› Â· log log ğ‘›)

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

Theorem 6. Any TreeEvalğ‘˜,â„ instance with â„ = ğ‘‚ (log ğ‘˜/log log ğ‘˜)

By Proposition 1, in total we need space

can be computed in L.

Another consequence is that if we convert our algorithms into
layered branching programs (see Section 7) computing TreeEvalğ‘˜,â„,
we can reduce the width to poly(ğ‘›) with no asymptotic loss in
length. We will not formally state or prove this result.

The proof of Theorem 5 is similar to that of Theorem 4, except
that instead of representing elements of [ğ‘˜] in binary, we represent
them as tuples of field elements for some larger field F âŠ† K. The
number of registers needed to represent elements of [ğ‘˜] will thus
shrink by a factor of log |F |. Our field K will be polynomially larger
than before (because the degree of the polynomial interpolated by
Lemma 10 grows with |F |), but since our space usage was ğ‘‚ ((â„ +
log ğ‘˜) Â· log |K |), i.e. our space only depends logarithmically on |K |,
this will ultimately not impact our asymptotics.

Proof of Theorem 5. Let F = F2ğ‘Ÿ and K = F2ğ‘Ÿğ‘  where ğ‘Ÿ and ğ‘ 
will be determined later. By Proposition 3 we may assume F âŠ† K.
An element of [ğ‘˜] can be represented using âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ elements
of F , but our registers will hold values in the larger field K.

The induction proof, after converting ğ‘“ğ‘¢ into polynomials ğ‘ğ‘¢,ğ‘– for
each ğ‘– âˆˆ [âŒˆlog ğ‘˜âŒ‰] as in the proof of Lemma 9, is the same as for The-
orem 4, except that instead of Lemma 9, we invoke Lemma 10 with
the two fields F âŠ† K, and with ğ‘“ğ‘¢ : F 2âŒˆ (log ğ‘˜ )/ğ‘Ÿ âŒ‰ â†’ F âŒˆ (log ğ‘˜ )/ğ‘Ÿ âŒ‰
working with encodings as elements of F instead of binary. Let
ğ‘¡ (â„â€²) be the length of the program for a node at height â„â€² â‰¤ â„. Then
the two children of a node at height â„â€² + 1 can be computed in time
2ğ‘¡ (â„â€²), so by Lemma 10,

ğ‘¡ (â„â€² + 1) â‰¤ 2|K | Â· ğ‘¡ (â„â€²) + poly(ğ‘˜)

and thus ğ‘¡ (â„) is at most (2|K |)ğ‘‚ (â„) poly(ğ‘˜).

Now we are ready to choose F = F2ğ‘Ÿ and K = F2ğ‘Ÿğ‘  . Our algo-
rithm uses 3âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ registers, each needing ğ‘Ÿğ‘  bits to store, for
a total of

3âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ Â· ğ‘Ÿğ‘  = ğ‘‚ (ğ‘  log ğ‘˜)

space devoted to storing registers. As stated above, the register
program has length (2|K |)ğ‘‚ (â„) poly(ğ‘˜), and so we need

log

(2 Â· 2ğ‘Ÿğ‘  )ğ‘‚ (â„) poly(ğ‘˜)

= ğ‘‚ (â„ğ‘Ÿğ‘  + log ğ‘˜)

space to track our position in the program.

(cid:16)

(cid:17)

Our register program is space ğ‘‚ (â„ log |K | + log ğ‘˜) = ğ‘‚ (â„ğ‘Ÿğ‘  +
log ğ‘˜) uniform. Recall (Definition 2) that to show this, we must
show that given (ğ‘¡, ğ‘¥), we can perform the ğ‘¡-th instruction on
input ğ‘¥ in space ğ‘‚ (â„ log |K | + log ğ‘˜). Similar to the argument in
Theorem 4, determining which instruction is the ğ‘¡-th can be done
in space ğ‘‚ (log ğ‘¡ (â„)) = ğ‘‚ (â„ log |K | + log ğ‘˜). Then, each individual
instruction can be computed in space ğ‘‚ (log |K | + log ğ‘˜). Looking
ahead to the program given in the proof of Lemma 10, lines 2 and
4 are field arithmetic operations which require ğ‘‚ (log |K |) space
(Proposition 2). Line 5 requires evaluating the polynomial ğ‘ğ‘– , which,
examining Equation 2, can be done by looping over all ğ‘˜ğ‘‚ (1) values
of (ğ‘§1 . . . ğ‘§ğ‘) in the sum, all ğ‘ = ğ‘‚ (log ğ‘˜) values for â„“ in the product,
and then looping up to |F | âˆ’ 1 to compute the exponent in ğ‘ğ‘§â„“ ,
plus ğ‘‚ (log |K |) space to do field arithmetic and store intermediate
results, for a total of ğ‘‚ (log |K | + log ğ‘˜) space.

ğ‘‚ (â„ğ‘Ÿğ‘  + log ğ‘˜) + ğ‘‚ (ğ‘  log ğ‘˜) = ğ‘‚ (â„ğ‘Ÿğ‘  + ğ‘  log ğ‘˜)

In order to use Lemma 10 we require

2âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ (2ğ‘Ÿ âˆ’ 1) < 2ğ‘Ÿğ‘  âˆ’ 1

Choosing ğ‘Ÿ = âŒˆlog log ğ‘˜âŒ‰ gives us

2âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ (2ğ‘Ÿ âˆ’ 1) â‰¤ 4(log ğ‘˜)2/log log ğ‘˜ < 22 log log ğ‘˜ âˆ’ 1

and thus choosing ğ‘  = 2 satisfies our condition, resulting in an
algorithm using space

ğ‘‚ (â„ğ‘Ÿğ‘  + ğ‘  log ğ‘˜) = ğ‘‚ (â„ log log ğ‘˜ + log ğ‘˜)

â–¡

The rest of the paper will focus on applications of Lemma 10, as
it will prove to be stronger and more flexible than Lemma 9 as seen
above. To end this section we will prove it, with a proof closely
mirroring that of Lemma 9.

Proof of Lemma 10. For each ğ‘– = 1 . . . ğ‘ we define a polynomial
ğ‘ğ‘– (ğ‘¦1 . . . ğ‘¦ğ‘) which computes the ğ‘–-th coordinate of ğ‘“ (ğ‘¦1 . . . ğ‘¦ğ‘).
Our inspiration will be the formula

ğ‘“ğ‘– (ğ‘¦1 . . . ğ‘¦ğ‘) =

ğ‘“ğ‘– (ğ‘§1 . . . ğ‘§ğ‘)

[ğ‘¦â„“ = ğ‘§â„“ ]

Ã•(ğ‘§1...ğ‘§ğ‘ ) âˆˆ Fğ‘

Ã–â„“=1

ğ‘

To make this a polynomial, we replace each indicator function
[ğ‘¦â„“ = ğ‘§â„“ ] with the polynomial

ğ‘ğ‘§â„“ (ğ‘¦â„“ ) = 1 âˆ’ (ğ‘¦â„“ âˆ’ ğ‘§â„“ ) | F | âˆ’1
ğ‘ğ‘§â„“ (ğ‘¦â„“ ) has degree |F | âˆ’ 1, and by Fermatâ€™s little theorem we have
ğ‘ğ‘§â„“ (ğ‘¦â„“ ) = [ğ‘¦â„“ = ğ‘§â„“ ] for any ğ‘¦â„“, ğ‘§â„“ âˆˆ F . Define

ğ‘

ğ‘ğ‘– (ğ‘¦1 . . . ğ‘¦ğ‘) =

ğ‘“ (ğ‘§1 . . . ğ‘§ğ‘)

ğ‘ğ‘§â„“ (ğ‘¦â„“ )

(2)

Ã•(ğ‘§1...ğ‘§ğ‘ ) âˆˆ Fğ‘

Ã–â„“=1

Thus ğ‘ğ‘– is a polynomial of degree ğ‘(|F | âˆ’ 1).

Now let ğ‘š = |K | âˆ’ 1 and let ğœ” be a primitive root of unity of
order ğ‘š in K. By assumption, ğ‘(|F | âˆ’ 1) < |K | âˆ’ 1, so ğ‘š is greater
than the degree of the polynomials ğ‘ğ‘– . Let ğœâ„“ âˆˆ K be the initial
value of each register ğ‘…â„“ . By Lemma 8,

âˆ’1 Â· ğ‘ğ‘– (ğœ” ğ‘—ğœ1 + ğ‘¦1 . . . ğœ” ğ‘—ğœğ‘ + ğ‘¦ğ‘) = ğ‘ğ‘– (ğ‘¦1 . . . ğ‘¦ğ‘)

ğ‘š

Ã•ğ‘—=1

This leads to the following algorithm. It replaces the inefficient
warm-up version presented in the proof of Lemma 9 which required
an extra ğ‘š copies of ğ‘ƒ âˆ’1
ğ‘” .
1: for ğ‘— = 1 . . . ğ‘š do
2:

ğ‘…â„“ â† (ğœ” âˆ’1 âˆ’ 1) âˆ’1 Â· ğ‘…â„“ for â„“ = 1 . . . ğ‘
ğ‘ƒğ‘”
ğ‘…â„“ â† (1 âˆ’ ğœ”) Â· ğ‘…â„“ for â„“ = 1 . . . ğ‘
ğ‘…ğ‘+ğ‘– â† ğ‘…ğ‘+ğ‘– + (âˆ’1) Â· ğ‘ğ‘– (ğ‘…1 . . . ğ‘…ğ‘) for ğ‘– = 1 . . . ğ‘
We may assume ğ‘š > 1 (otherwise ğ‘ğ‘– has degree 0, so is a constant),
so ğœ” â‰  1 and (ğœ” âˆ’1 âˆ’ 1) âˆ’1 exists and can be used on line 2.

3:

5:

4:

To analyse this algorithm, define ğœ â€²
â„“

= ğœâ„“ âˆ’ ğ‘”â„“ for â„“ = 1 . . . ğ‘. At
the start of the ğ‘—-th iteration of the loop, the following invariants
hold for â„“ âˆˆ [ğ‘], ğ‘– âˆˆ [ğ‘]:

ğ‘…â„“ =ğœ” ğ‘— âˆ’1ğœ â€²

â„“ + ğ‘”â„“

1274

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

James Cook and Ian Mertz

ğ‘…ğ‘+ğ‘– =ğœğ‘+ğ‘– +

ğ‘— âˆ’1

Ã•ğ‘— â€²=1

âˆ’1 Â· ğ‘ğ‘– (ğœ” ğ‘— â€²

1 + ğ‘”1, . . . , ğœ” ğ‘— â€²
ğœ â€²

ğœ â€²
ğ‘ + ğ‘”ğ‘)

It is straightforward to verify this invariant holds after each itera-
tion. After the last iteration, Lemma 8 tells us that for â„“ âˆˆ [ğ‘], ğ‘– âˆˆ [ğ‘]

ğ‘…â„“ =ğœ”ğ‘šğœ â€²

â„“ + ğ‘”â„“
=ğœâ„“ âˆ’ ğ‘”â„“ + ğ‘”â„“ = ğœâ„“
ğ‘š

Ã•ğ‘—=1
=ğœğ‘+ğ‘– + ğ‘ğ‘– (ğ‘”1 . . . ğ‘”ğ‘)

ğ‘…ğ‘+ğ‘– =ğœğ‘+ğ‘– +

âˆ’1 Â· ğ‘ğ‘– (ğœ” ğ‘—ğœ â€²

1 + ğ‘”1, . . . , ğœ” ğ‘—ğœ â€²

ğ‘ + ğ‘”ğ‘)

This register program includes ğ‘š copies of ğ‘ƒğ‘” and has a total
â–¡

length of ğ‘š(2ğ‘ + ğ‘ + ğ‘¡ (ğ‘ƒğ‘”)).

6 APPLICATION 1: THE KRW CONJECTURE

SEPARATES L AND NC1

We now move on to applications of the statement and proof of
Theorem 1. In this section we study its implications in the study of
formula lower bounds.

6.1 KRW and TEP
To begin, we formally state the KRW conjecture to fit the discussion
from Section 1.

Conjecture 1 (KRW Conjecture [21]). For a function ğ‘“ , let ğ‘‘ğ‘’ğ‘ğ‘¡â„(ğ‘“ )
denote the smallest depth of any fan-in two formula computing ğ‘“ .
For any functions ğ‘”1 : {0, 1}ğ‘›1 â†’ {0, 1} and ğ‘”2 : {0, 1}ğ‘›2 â†’ {0, 1},
define their composition to be
ğ‘”1 â—¦ğ‘”2 (ğ‘¥1,1 . . . ğ‘¥ğ‘›1,ğ‘›2 ) := ğ‘”1 (ğ‘”2 (ğ‘¥1,1 . . . ğ‘¥1,ğ‘›2 ) . . . ğ‘”2 (ğ‘¥ğ‘›1,1 . . . ğ‘¥ğ‘›1,ğ‘›2 ))
Then for almost all functions ğ‘”1, ğ‘”2, it holds that

ğ‘‘ğ‘’ğ‘ğ‘¡â„(ğ‘”1 â—¦ ğ‘”2) â‰¥ ğ‘‘ğ‘’ğ‘ğ‘¡â„(ğ‘”1) + ğ‘‘ğ‘’ğ‘ğ‘¡â„(ğ‘”2) âˆ’ ğ‘‚ (1)
We note that this conjecture can be weakened by increasing the ğ‘‚ (1)
subtractive term.

To see why this is connected to TreeEval, we need to consider
the unbounded fan-in version of TreeEval. A TreeEvalğ‘˜,ğ‘‘,â„ instance
is as before, a tree of height â„ and using alphabet size ğ‘˜, but now
each internal node has ğ‘‘ children rather than 2.
Lemma 11. Conjecture 1 implies ğ‘‘ğ‘’ğ‘ğ‘¡â„(TreeEval2,ğ‘‘,â„) = Î©(ğ‘‘â„).
Proof. For each layer â„“ âˆˆ [â„], pick a random function ğ‘“â„“
:
{0, 1}ğ‘‘ â†’ {0, 1}, and fix each internal TreeEval2,ğ‘‘,â„ node at height
â„“ to ğ‘“â„“ . By a counting argument, each ğ‘“â„“ requires formula depth
Î©(ğ‘‘) with high probability. We apply the KRW Conjecture first
to ğ‘”1 = ğ‘“1 and ğ‘”2 = ğ‘“2, then ğ‘”1 = ğ‘“1 â—¦ ğ‘“2 and ğ‘”2 = ğ‘“3, and so on
â„ âˆ’ 1 times, until we ultimately get that the composition of all
ğ‘“â„“ â€”which is to say, the TreeEval2,ğ‘‘,â„ instance in questionâ€”requires
â–¡
depth Î©(ğ‘‘â„).

Since TreeEvalğ‘˜,ğ‘‘,â„ has input size ğ‘› = ğ‘‘â„ğ‘˜ğ‘‘ log ğ‘˜, fixing ğ‘˜ =
2 gives us log ğ‘› = ğ‘‚ (â„ log ğ‘‘ + ğ‘‘), which implies that Î©(ğ‘‘â„) =
ğœ” (log ğ‘›)â€”and thus TreeEval2,ğ‘‘,â„ âˆ‰ NC1, assuming Conjecture 1â€”
for the right setting of parameters. We give exact details after estab-
lishing the other side of Theorem 2, namely the space complexity
of TreeEval2,ğ‘‘,â„.

1275

6.2 Space Bounds for TreeEvalğ‘˜,ğ‘‘,â„
Using Lemma 10, we can generalize Theorem 1, and in fact Theo-
rem 5, to degrees ğ‘‘ other than 2:

Theorem 7. Any TreeEvalğ‘˜,ğ‘‘,â„ instance can be computed in space

ğ‘‚ (â„ log(ğ‘‘ log ğ‘˜) + ğ‘‘ log ğ‘˜).

Proof. The proof is the same as for Theorem 5 but with ğ‘‘ inputs
instead of 2. Let F = F2ğ‘Ÿ and K = F2ğ‘Ÿğ‘  where ğ‘Ÿ and ğ‘  will be
determined later. As before, we represent elements of [ğ‘˜] as tuples
of âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ field elements, and consider the function at node
ğ‘¢ as ğ‘“ğ‘¢ : F ğ‘‘ âŒˆ (log ğ‘˜ )/ğ‘Ÿ âŒ‰ â†’ F âŒˆ (log ğ‘˜ )/ğ‘Ÿ âŒ‰ . Our algorithm uses (ğ‘‘ +
1) âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ registers, each needing ğ‘Ÿğ‘  bits to store, for a total of

(ğ‘‘ + 1) âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ Â· ğ‘Ÿğ‘  = ğ‘‚ (ğ‘‘ğ‘  log ğ‘˜)

space devoted to storing registers. Using Lemma 10, we get a register
program of length (ğ‘‘ |K |)ğ‘‚ (â„) poly(ğ‘˜) (in this case the program ğ‘ƒğ‘”
in Lemma 10 must evaluate all ğ‘‘ children, hence the ğ‘‘ in the base
of the exponent), and so we need

log

(ğ‘‘2ğ‘Ÿğ‘  )ğ‘‚ (â„) poly(ğ‘˜)

= ğ‘‚ (â„ğ‘Ÿğ‘  + â„ log ğ‘‘ + log ğ‘˜)

(cid:17)
space to track our position in the program. Lastly our program is

(cid:16)

ğ‘‚ (â„ğ‘Ÿğ‘  + â„ log ğ‘‘ + log ğ‘˜ + ğ‘‘ âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ğ‘Ÿ ) = ğ‘‚ (â„ğ‘Ÿğ‘  + â„ log ğ‘‘ + ğ‘‘ log ğ‘˜)

uniform by the same argument as in Theorem 4 and 5. By Proposi-
tion 1, in total we need space

ğ‘‚ (â„ğ‘Ÿğ‘  + â„ log ğ‘‘ + log ğ‘˜) + ğ‘‚ (ğ‘‘ğ‘  log ğ‘˜) + ğ‘‚ (â„ğ‘Ÿğ‘  + â„ log ğ‘‘ + ğ‘‘ log ğ‘˜)
=ğ‘‚ (â„ğ‘Ÿğ‘  + â„ log ğ‘‘ + ğ‘‘ğ‘  log ğ‘˜)

In order to use Lemma 10 we require

ğ‘‘ âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ (2ğ‘Ÿ âˆ’ 1) < 2ğ‘Ÿğ‘  âˆ’ 1
Let ğ‘Ÿ = âŒˆlog(ğ‘‘ log ğ‘˜)âŒ‰ and ğ‘  = 2. This will result in an algorithm
using space

(3)

ğ‘‚ (â„ğ‘Ÿğ‘  + â„ log ğ‘‘ + ğ‘‘ğ‘  log ğ‘˜) = ğ‘‚ (â„ log(ğ‘‘ log ğ‘˜) + ğ‘‘ log ğ‘˜)

It remains to show (3), which we do by considering two cases. If
ğ‘Ÿ â‰¤ log ğ‘˜, then for sufficiently large ğ‘‘ log ğ‘˜,
ğ‘‘ âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ (2ğ‘Ÿ âˆ’1) â‰¤ 4(ğ‘‘ log ğ‘˜)2/log(ğ‘‘ log ğ‘˜) < 2âŒˆ2 log(ğ‘‘ log ğ‘˜ ) âŒ‰ âˆ’1
Otherwise (ğ‘Ÿ > log ğ‘˜),

ğ‘‘ âŒˆ(log ğ‘˜)/ğ‘Ÿ âŒ‰ (2ğ‘Ÿ âˆ’ 1) â‰¤ğ‘‘2ğ‘Ÿ âˆ’ 1

=2âŒˆlog(ğ‘‘ log ğ‘˜ ) âŒ‰+log ğ‘‘ âˆ’ 1
â‰¤22âŒˆlog(ğ‘‘ log ğ‘˜ ) âŒ‰ âˆ’ 1

â–¡

6.3 Main Result
The input to TreeEvalğ‘˜,ğ‘‘,â„ is of length ğ‘‘â„ Â· ğ‘˜ğ‘‘ log ğ‘˜, and thus The-
orem 7 gives us an algorithm using space ğ‘‚ (log ğ‘› Â· log log ğ‘›) for
every setting of ğ‘˜, ğ‘‘, and â„. As with Theorem 6, this also shows
that some parameterizations of TreeEvalğ‘˜,ğ‘‘,â„ are easy.

Theorem 8. Any TreeEvalğ‘˜,ğ‘‘,â„ instance with ğ‘‘ â‰¥ (log ğ‘˜)Î© (1) can

be computed in L.

Proof. Theorem 7 gives an algorithm for TreeEvalğ‘˜,ğ‘‘,â„ which
uses space ğ‘‚ (â„ log(ğ‘‘ log ğ‘˜) + ğ‘‘ log ğ‘˜), which for log ğ‘˜ â‰¤ ğ‘‘ğ‘‚ (1) is at
â–¡
most ğ‘‚ (â„ log ğ‘‘ + ğ‘‘ log ğ‘˜) = ğ‘‚ (log(ğ‘‘â„ Â· ğ‘˜ğ‘‘ log ğ‘˜)).

Tree Evaluation Is in Space ğ‘‚ (log ğ‘› Â· log log ğ‘›)

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

This immediately yields Theorem 2, which we state in a more

quantitative form.

Theorem 9. Assume Conjecture 1 holds. Then there exists a func-

tion in L which requires formulas of depth Î©(log2 ğ‘›/log log ğ‘›).

Proof. Let ğ‘‘ = Î˜(log ğ‘›) and â„ = Î˜(log ğ‘›/log log ğ‘›) be such
that ğ‘‘â„ Â· 2ğ‘‘ = ğ‘›. Then by Theorem 8 we have TreeEval2,ğ‘‘,â„ âˆˆ L,
while Lemma 11 states that TreeEval2,ğ‘‘,â„ requires depth Î©(ğ‘‘â„) =
Î©(log2 ğ‘›/log log ğ‘›) as claimed.
â–¡

Theorem 9 applies to the strongest case of Conjecture 1, but
as stated in the introduction, any weakening which implies that
TreeEval2,ğ‘‘,â„ requires superlogarithmic formula depth is sufficient,
with the lower bound derived translating to one of equal asymp-
totics against L.

7 APPLICATION 2: NEAR-OPTIMAL

CATALYTIC BRANCHING PROGRAMS

Our second contribution outside of TreeEval is to the study of
catalytic branching programs for computing arbitrary functions.

7.1 Catalytic Branching Programs
7.1.1 Definitions and Motivation. We have thus far avoided dis-
cussing any syntactic space-bounded models except in passing.
While we assume familiarity on the part of the reader with branch-
ing programs in the usual sense, to understand our second auxiliary
result we must formally define the model of [15] now.

Definition 6. Let ğ‘› âˆˆ N and let ğ‘“ : {0, 1}ğ‘› â†’ {0, 1} be an arbitrary
function. An ğ‘š-catalytic branching program is a directed acyclic
graph ğº with the following properties:

â€¢ There are ğ‘š source nodes and 2ğ‘š sink nodes.
â€¢ Every non-sink node is labeled with an input variable ğ‘¥ğ‘– for

ğ‘– âˆˆ [ğ‘›], and has two outgoing edges labeled 0 and 1.

â€¢ For every source node ğ‘£ there is one sink node labeled with

(ğ‘£, 0) and one with (ğ‘£, 1).

We say that ğº computes ğ‘“ if for every ğ‘¥ âˆˆ {0, 1}ğ‘› and source node
ğ‘£, the path defined by starting at ğ‘£ and following the edges labeled
by the value of the ğ‘¥ğ‘– labeling each node ends at the sink labeled
by (ğ‘£, ğ‘“ (ğ‘¥)).

The size of ğº is the number of nodes in ğº. For this paper all
branching programs will be layered, meaning all nodes are orga-
nized into groups, called layers, where all edges from layer ğ‘– go to
nodes in layer ğ‘– + 1 for all ğ‘–. The width of ğº is the largest size of any
layer, while the length of ğº is the number of layers.

The (logarithm of the) size of an ordinary branching program
computing ğ‘“ non-uniformly corresponds to the space needed to
compute ğ‘“ , as we need only remember where in the program we
currently are. By contrast, the reader should think of the ğ‘š-catalytic
branching program model as providing some initial memory ğœ in
the form of the label of some start node, and the (logarithm of
the) size of the program is the space required to compute ğ‘“ while
remembering this string ğœ.

Clearly this can be done with ğ‘ ğ‘š nodes, where ğ‘  is the size of
the smallest branching program for ğ‘“ , by simply taking ğ‘š disjoint
copies of an optimal branching program for ğ‘“ ; we are interested

in when this value can be reduced. This corresponds to using the
space needed to store ğœ in a non-trivial way during the computation
of ğ‘“ . This view also motivated Potechin [24] to alternately view
catalytic branching programs as amortized branching programs, as
we can think of taking these ğ‘š disjoint branching programs for ğ‘“
and letting them share memory states, i.e. internal nodes, while
still preserving the same disjoint source-sink behavior.

7.1.2 Past Results. In addition to characterizing ğ‘š-catalytic branch-
ing programs as amortized branching programs, Potechin [24]
showed that, given enough amortization, every function can be
computed by branching programs of amortized linear size. Robere
and Zuiddam [27] studied two different amortized branching pro-
gram models, with one being catalytic branching programs, and
concluded along with [24] that a linear upper bound holds; they
also improved the amount of amortization needed for functions ğ‘“
that can be represented as low-degree F2 polynomials.

Later, Cook and Mertz [9] showed the results of [24, 27] can
be captured by clean register programs. As with traditional space,
clean register programs can utilize this initial memory ğœ as the
setting of its registers at the beginning of the program, with the
clean condition exactly giving back the pairing between source and
sink nodes.

Proposition 12. Let ğ‘“ : {0, 1}ğ‘› â†’ {0, 1} be a function, let F be
a finite field of characteristic ğ‘. Assume that there exists a register
program ğ‘ƒ using ğ‘¡ instructionsâ€”each of which only reads one input
bit5â€”and ğ‘  registers over F , whose net result is to cleanly compute
ğ‘“ into some register. Then ğ‘“ can be computed by an ğ‘š-catalytic
branching program of width ğ‘š Â· ğ‘ and length ğ‘¡, where ğ‘š = |F |ğ‘  /ğ‘.

Proof. Each of the |F |ğ‘  nodes in a given layer will represent a
unique setting to all the registers. We will execute one instruction of
the register program per layer, querying the input bit corresponding
to that instruction.

Finally, we will consider, for each source and sink node, the
corresponding assignment to the designated output register. Find
a basis {ğ‘’1 . . . ğ‘’ğ‘Ÿ } for F considered as a vector space over Fğ‘ such
that ğ‘’1 is the field element 1 âˆˆ F . We delete all source nodes except
those whose first coordinate is 0â€”leaving us with |F |ğ‘  /ğ‘ source
nodes as claimedâ€”and similarly we delete all sink nodes except
those whose corresponding assignment to the first coordinate is
either 0 or 1. By construction, each source whose assignment is
ğœ will reach the sink node labeled by the same ğœ, except that if
ğ‘“ (ğ‘¥1, . . . , ğ‘¥ğ‘›) = 1, then 1 is added to the output register, so that the
â–¡
its first coordinate is 1 instead of 0.

In [24, 27], the amount of amortization required to achieve linear
upper bounds was 22ğ‘›
in the worst case. Using Proposition 12 plus
the central TreeEval subroutines of [7, 8], [9] improved this to 22ğœ–ğ‘›
for any ğœ– > 0. This is still the best known result for achieving linear
amortized braching program size.

We also mention in passing that the ğ‘š-catalytic branching pro-
grams produced by Proposition 12 can be made into permutation

5This is different from our earlier condition, given by Proposition 1, that each in-
struction be computable in small space. In non-uniform models we can compute any
function of the current space in one step, but need to take careful account of the length
as the exact number of variable reads.

1276

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

James Cook and Ian Mertz

branching programsâ€”a classic and much more well-studied modelâ€”
of the same width and length. In fact they are more restricted,
and for example only have one accepting vertex; recently, Hoza,
Pyne, and Vadhan [19] and Pyne and Vadhan [25] showed a lower
bound against the read-once version of such programs for infinite
width. See [9] for more discussion of the connections between these
models and of how close to read-once our programs can be made.

7.2 One-Shot Clean Polynomials
Given our connection between register programs and ğ‘š-catalytic
branching programs, and the fact that Lemma 10 gives us a way
to cleanly compute arbitrary polynomials, it seems natural to ask
whether our techniques can improve the parameters of computing
arbitrary functions using ğ‘š-catalytic branching programs. This
will require us to leave behind our strategy of using Lemma 10 in a
recursive way, and instead apply it directly to the whole function ğ‘“
in question.

Using this idea to prove Theorem 3 will be the subject of the rest
of the section; we will prove a more general, fine-grained version.

Theorem 10. Let ğ‘“ be any function on ğ‘› bits, and let ğ‘Ÿ, ğ‘  be positive

integers such that

âŒˆğ‘›/ğ‘Ÿ âŒ‰ (2ğ‘Ÿ âˆ’ 1) < 2ğ‘Ÿğ‘  âˆ’ 1

Then there exists an ğ‘š-catalytic branching program of width 2ğ‘š and
length 2ğ‘Ÿğ‘ ğ‘›(1 + 2/ğ‘Ÿ + 3/ğ‘›) computing ğ‘“ , where ğ‘š â‰¤ 2(ğ‘›+2ğ‘Ÿ )ğ‘  .

Proof. Let F = F2ğ‘Ÿ and K = F2ğ‘Ÿğ‘  . We will group the input into
groups of ğ‘Ÿ bits, and encode each group of bits as an element of
F = F2ğ‘Ÿ . This grouping and encoding together define a function
ğ‘” : {0, 1}ğ‘› â†’ F âŒˆğ‘›/ğ‘Ÿ âŒ‰ , which will play the role of ğ‘” in the statement
of Lemma 10, with ğ‘ = âŒˆğ‘›/ğ‘Ÿ âŒ‰. The program ğ‘ƒğ‘” (which cleanly
computes ğ‘”) can be implemented as a sequence of ğ‘› instructions,
reading each input once.

Applying Lemma 10 gives a register program of length

Proof of Theorem 3. We analyze three ways to choose ğ‘Ÿ and ğ‘ 
to satisfy the precondition of Theorem 10, each corresponding to
one claim of the theorem.6

Constant ğ‘ . Let ğ‘  be any integer greater than 1. We consider two

settings, ğ‘  = 2 and ğ‘  â‰¥ 3. In the latter case, let

ğ‘Ÿ =

1
ğ‘  âˆ’ 1

log ğ‘›

< 1

ğ‘  âˆ’ 1

log ğ‘› + 1

(cid:24)

(cid:25)
Then the length of the program given by Theorem 10 is at most
2ğ‘Ÿğ‘ ğ‘›(1 + 2/ğ‘Ÿ + 3/ğ‘›) â‰¤ 2ğ‘  Â· 2(ğ‘ /(ğ‘  âˆ’1) ) log ğ‘› Â· ğ‘› Â· (1 + ğ‘œ (1))

and for ğ‘š we have

= (2ğ‘  + ğ‘œ (1))ğ‘› (2ğ‘  âˆ’1)/(ğ‘  âˆ’1)

ğ‘š â‰¤ 2(ğ‘›+2ğ‘Ÿ )ğ‘ 

< 2(ğ‘›+2)ğ‘  Â· ğ‘›2ğ‘ /(ğ‘  âˆ’1)

Let ğœ– = 1
(21+1/ğœ– + ğ‘œ (1)) Â· ğ‘›2+ğœ– = ğ‘‚ (ğ‘›2+ğœ– ) and ğ‘š at most

ğ‘  âˆ’1 âˆˆ (0, 1/2], so ğ‘  = 1 + 1/ğœ–. This gives us length at most

2(ğ‘›+2) (1+1/ğœ– )ğ‘›2(1+ğœ– ) < 2(1+1/ğœ–+ğ‘œ (1) )ğ‘›

which gives us the first program of Theorem 3. Note that ğœ– can be
made arbitrarily small by increasing ğ‘ .

For the second program, we move to the ğ‘  = 2 case. Fix ğ‘Ÿ =
âŒˆlog ğ‘› âˆ’ log log ğ‘› + 1âŒ‰ < log ğ‘› âˆ’ log log ğ‘› + 2. Our length is at most
2ğ‘Ÿğ‘ ğ‘›(1 + 2/ğ‘Ÿ + 3/ğ‘›) â‰¤ 22(log ğ‘›âˆ’log log ğ‘›+2)ğ‘›(1 + ğ‘œ (1))

= (16 + ğ‘œ (1))

ğ‘›3
log2 ğ‘› (cid:19)

(cid:18)

while for ğ‘š we have

ğ‘š â‰¤ 22(ğ‘›+2ğ‘Ÿ )

< 22(ğ‘›+2 log ğ‘›âˆ’2 log log ğ‘›+4)

= 28 Â· 22ğ‘›

ğ‘›
log ğ‘›

(cid:18)

4

(cid:19)

(|K | âˆ’ 1)(ğ‘¡ (ğ‘ƒğ‘”) + 2ğ‘ + ğ‘) = (2ğ‘Ÿğ‘  âˆ’ 1)(ğ‘› + 2âŒˆğ‘›/ğ‘Ÿ âŒ‰ + 1)

Constant ğ‘Ÿ . Let ğ‘Ÿ be any integer greater than 1, and set

< 2ğ‘Ÿğ‘ ğ‘›(1 + 2/ğ‘Ÿ + 3/ğ‘›)

ğ‘  =

which uses

ğ‘ + ğ‘ = âŒˆğ‘›/ğ‘Ÿ âŒ‰ + 1

registers over K. By Proposition 12, this gives us an ğ‘š-catalytic
branching program of length 2ğ‘Ÿğ‘ ğ‘›(1 + 2/ğ‘Ÿ + 3/ğ‘›) and width 2ğ‘š,
where

ğ‘š = |K | âŒˆğ‘›/ğ‘Ÿ âŒ‰+1/2 = (2ğ‘Ÿğ‘  ) âŒˆğ‘›/ğ‘Ÿ âŒ‰+1/2 < 2(ğ‘›+2ğ‘Ÿ )ğ‘ 

Finally Lemma 10 requires ğ‘(|F | âˆ’ 1) < |K | âˆ’ 1; that is,

âŒˆğ‘›/ğ‘Ÿ âŒ‰ (2ğ‘Ÿ âˆ’ 1) < 2ğ‘Ÿğ‘  âˆ’ 1

which completes the proof.

â–¡

7.3 Main Result
Theorem 3 will follow by analyzing various parameter regimes
from Theorem 10.

log ğ‘› âˆ’ log ğ‘Ÿ
ğ‘Ÿ

+

1
ğ‘›

+ 1 < log ğ‘› âˆ’ log ğ‘Ÿ

+

ğ‘Ÿ

1
ğ‘›

+ 2

(cid:24)
Thus our length is at most
2ğ‘Ÿğ‘ ğ‘›(1 + 2/ğ‘Ÿ + 3/ğ‘›) < 2ğ‘Ÿ ( (log ğ‘›âˆ’log ğ‘Ÿ )/ğ‘Ÿ +(1/ğ‘›)+2)ğ‘›(1 + 2/ğ‘Ÿ + 3/ğ‘›)

(cid:25)

=

ğ‘›
ğ‘Ÿ

Â· 2ğ‘Ÿ /ğ‘› Â· 22ğ‘Ÿ Â· ğ‘› Â· (1 + 2/ğ‘Ÿ + 3/ğ‘›)

â‰¤ (1 + ğ‘œ (1))

22ğ‘Ÿ

(cid:18)
â‰¤ (1 + ğ‘œ (1))22ğ‘Ÿ ğ‘›2

(cid:18)

1
ğ‘Ÿ

+

2
ğ‘Ÿ 2

ğ‘›2

(cid:19)

(cid:19)

and for the width we get

ğ‘š < 2(ğ‘›+2ğ‘Ÿ ) ( (log ğ‘›âˆ’log ğ‘Ÿ )/ğ‘Ÿ +1/ğ‘›+2)
â‰¤ 2(ğ‘› log ğ‘›)/ğ‘Ÿ +ğ‘› (2âˆ’ (log ğ‘Ÿ )/ğ‘Ÿ +ğ‘œ (1) )
Setting ğœ– = 1/ğ‘Ÿ gives us our third programâ€”ğœ– can be made arbitrar-
â–¡
ily small by increasing ğ‘Ÿ â€”which completes the proof.

6In what follows, all asymptotics (ğ‘‚ ( ), ğ‘œ ( )) take ğ‘› as the growing variable, with either
ğ‘Ÿ or ğ‘  fixed and the other a function of ğ‘›.

1277

Tree Evaluation Is in Space ğ‘‚ (log ğ‘› Â· log log ğ‘›)

STOC â€™24, June 24â€“28, 2024, Vancouver, BC, Canada

8 CONCLUSION
The most immediate question left open by this work is whether or
not TreeEval âˆˆ L. Both answers are entirely possible, and it is no
longer clear why one should be wholly convinced of either.

Similarly, we may take the chance to consider what answer we
might expect on the KRW conjecture. We have stated Theorem 2
about the implications of composition theorems for formulas, but
since our main theorem can and should be read as a failure of com-
position theorems in the space-bounded case, it is natural, possibly
more so than before, to also believe that they could fail for formulas
as well. Here one should read the contrapositive of Theorem 2 as
giving a different angle: if one can show that deterministic uniform
logspace has formulas of depth ğ‘œ (log2 ğ‘›/log log ğ‘›)â€”barely above
the bound given by Savitchâ€™s Theorem [28] for non-deterministic
non-uniform spaceâ€”then the KRW conjecture falls in tandem.

There is also a broader question of how to apply our techniques
to other problems in space-bounded complexity. The result of
Lemma 10, of cleanly and efficiently computing arbitrary poly-
nomials, seems to be a heavy hammer, but thus far it has only
found a few nails.

Recently, Mertz [23] surveyed a number of techniques for space-
bounded complexity, including the use of clean register programs
seen in this and previous papers. The survey posed a host of open
questions of how they can be further strengthened and applied, such
as showing the power of catalytic computing. To take one example
where our results may be relevant, they conjecture that an optimal
improvement to Lemma 9 could also show that catalytic logspace
contains NC2. However, whether our more modest improvement
in this paper can be useful in making progress on this or any other
questions posed remains unknown.

ACKNOWLEDGMENTS
The authors would like to thank Robert Robere, Bruno Loff, and
Manuel Stoeckl for many insightful discussions, as well as Igor
Oliveira, Ninad Rajgopal, Pierre McKenzie, and the reviewers of
ECCC and STOC for feedback on earlier drafts. The second author
received support from the Royal Society University Research Fellow-
ship URF\R1\191059 and from the Centre for Discrete Mathematics
and its Applications (DIMAP) at the University of Warwick.

REFERENCES
[1] David A. Mix Barrington. 1989. Bounded-Width Polynomial-Size Branching
Programs Recognize Exactly Those Languages in NC1. J. Comput. Syst. Sci. 38, 1
(1989), 150â€“164. https://doi.org/10.1016/0022-0000(89)90037-8

[2] Michael Ben-Or and Richard Cleve. 1992. Computing Algebraic Formulas Using
a Constant Number of Registers. SIAM J. Comput. 21, 1 (1992), 54â€“58. https:
//doi.org/10.1137/0221006

[3] Sagar Bisoyi, Krishnamoorthy Dinesh, and Jayalal Sarma. 2022. On pure space
vs catalytic space. Theor. Comput. Sci. 921 (2022), 112â€“126. https://doi.org/10.
1016/J.TCS.2022.04.005

[4] Harry Buhrman, Richard Cleve, Michal KouckÃ½, Bruno Loff, and Florian Speelman.
2014. Computing with a full memory: catalytic space. In Symposium on Theory of
Computing, STOC 2014. ACM, 857â€“866. https://doi.org/10.1145/2591796.2591874
[5] Harry Buhrman, Michal KouckÃ½, Bruno Loff, and Florian Speelman. 2018. Cat-
alytic Space: Non-determinism and Hierarchy. Theory Comput. Syst. 62, 1 (2018),
116â€“135. https://doi.org/10.1007/S00224-017-9784-7

[6] Arkadev Chattopadhyay, Yuval Filmus, Sajin Koroth, Or Meir, and Toniann Pitassi.
2021. Query-to-Communication Lifting Using Low-Discrepancy Gadgets. SIAM

J. Comput. 50, 1 (2021), 171â€“210. https://doi.org/10.1137/19M1310153

[7] James Cook and Ian Mertz. 2020. Catalytic approaches to the tree evaluation prob-
lem. In Proceedings of the 52nd Annual ACM Symposium on Theory of Computing,
STOC 2020. ACM, 752â€“760. https://doi.org/10.1145/3357713.3384316

[8] James Cook and Ian Mertz. 2021. Encodings and the Tree Evaluation Problem.
Electron. Colloquium Comput. Complex. (2021), 54. https://eccc.weizmann.ac.il/
report/2021/054

[9] James Cook and Ian Mertz. 2022. Trading Time and Space in Catalytic Branch-
ing Programs. In 37th Computational Complexity Conference, CCC 2022 (LIPIcs,
Vol. 234). 8:1â€“8:21. https://doi.org/10.4230/LIPIcs.CCC.2022.8

[10] Stephen A. Cook, Pierre McKenzie, Dustin Wehr, Mark Braverman, and Rahul
Santhanam. 2012. Pebbles and Branching Programs for Tree Evaluation. ACM
Trans. Comput. Theory 3, 2 (2012), 4:1â€“4:43. https://doi.org/10.1145/2077336.
2077337

[11] Don Coppersmith and Edna K. Grossman. 1975. Generators for Certain Alter-
nating Groups with Applications to Cryptography. Siam Journal on Applied
Mathematics 29 (1975), 624â€“627. https://doi.org/10.1137/0129051

[12] Samir Datta, Chetan Gupta, Rahul Jain, Vimal Raj Sharma, and Raghunath Tewari.
2020. Randomized and Symmetric Catalytic Computation. In CSR (Lecture Notes
in Computer Science, Vol. 12159). Springer, 211â€“223. https://doi.org/10.1007/978-
3-030-50026-9_15

[13] Susanna F. de Rezende, Or Meir, Jakob NordstrÃ¶m, Toniann Pitassi, and Robert
Robere. 2020. KRW Composition Theorems via Lifting. In FOCS. IEEE, 43â€“49.
https://doi.org/10.1109/FOCS46700.2020.00013

[14] Jeff Edmonds, Venkatesh Medabalimi, and Toniann Pitassi. 2018. Hardness of
Function Composition for Semantic Read once Branching Programs. In 33rd Com-
putational Complexity Conference, CCC 2018 (LIPIcs, Vol. 102). Schloss Dagstuhl
- Leibniz-Zentrum fÃ¼r Informatik, 15:1â€“15:22. https://doi.org/10.4230/LIPICS.
ICALP.2016.36

[15] Vincent Girard, Michal KouckÃ½, and Pierre McKenzie. 2015. Nonuniform catalytic
space and the direct sum for space. Electronic Colloquium on Computational
Complexity (ECCC) 138 (2015).

[16] Mika GÃ¶Ã¶s, Toniann Pitassi, and Thomas Watson. 2018. Deterministic Com-
munication vs. Partition Number. SIAM J. Comput. 47, 6 (2018), 2435â€“2450.
https://doi.org/10.1137/16M1059369

[17] Chetan Gupta, Rahul Jain, Vimal Raj Sharma, and Raghunath Tewari. 2019. Un-
ambiguous Catalytic Computation. In 39th IARCS Annual Conference on Foun-
dations of Software Technology and Theoretical Computer Science, FSTTCS 2019
(LIPIcs, Vol. 150). Schloss Dagstuhl - Leibniz-Zentrum fÃ¼r Informatik, 16:1â€“16:13.
https://doi.org/10.4230/LIPIcs.FSTTCS.2019.16

[18] John E. Hopcroft, Wolfgang J. Paul, and Leslie G. Valiant. 1977. On Time Versus
Space. J. ACM 24, 2 (1977), 332â€“337. https://doi.org/10.1145/322003.322015
[19] William Hoza, Edward Pyne, and Salil Vadhan. 2021. Pseudorandom generators
for unbounded-width permutation branching programs. In 12th Innovations in
Theoretical Computer Science (ITCSâ€™21) (LIPIcs). https://doi.org/10.4230/LIPIcs.
ITCS.2021.7

[20] Kazuo Iwama and Atsuki Nagao. 2019. Read-Once Branching Programs for
Tree Evaluation Problems. ACM Trans. Comput. Theory 11, 1 (2019), 5:1â€“5:12.
https://doi.org/10.1145/3282433

[21] Mauricio Karchmer, Ran Raz, and Avi Wigderson. 1995. Super-Logarithmic Depth
Lower Bounds Via the Direct Sum in Communication Complexity. Comput.
Complex. 5, 3/4 (1995), 191â€“204. https://doi.org/10.1007/BF01206317

[22] David Liu. 2013. Pebbling Arguments for Tree Evaluation. CoRR abs/1311.0293

(2013). https://doi.org/10.48550/arXiv.1311.0293

[23] Ian Mertz. 2023. Reusing Space: Techniques and Open Problems. B.EATCS 141

(2023), 57â€“106.

[24] Aaron Potechin. 2017. A Note on Amortized Branching Program Complexity. In
Computational Complexity Conference (LIPIcs, Vol. 79). Schloss Dagstuhl - Leibniz-
Zentrum fÃ¼r Informatik, 4:1â€“4:12. https://doi.org/10.4230/LIPIcs.CCC.2017.4

[25] Edward Pyne and Salil Vadhan. 2021. Pseudodistributions That Beat All Pseu-
dorandom Generators (Extended Abstract). In 36th Computational Complex-
ity Conference (CCCâ€™21). Schloss Dagstuhl - Leibniz-Zentrum fÃ¼r Informatik.
https://doi.org/10.4230/LIPIcs.CCC.2021.33

[26] Ran Raz and Pierre McKenzie. 1999. Separation of the Monotone NC Hierarchy.

Comb. 19, 3 (1999), 403â€“435. https://doi.org/10.1007/S004930050062

[27] Robert Robere and Jeroen Zuiddam. 2021. Amortized Circuit Complexity, Formal
Complexity Measures, and Catalytic Algorithms. In FOCS. IEEE, 759â€“769. https:
//doi.org/10.1109/FOCS52979.2021.00079

[28] Walter J. Savitch. 1970. Relationships Between Nondeterministic and Deter-
ministic Tape Complexities. J. Comput. Syst. Sci. 4, 2 (1970), 177â€“192. https:
//doi.org/10.1016/S0022-0000(70)80006-X

Received 12-NOV-2023; accepted 2024-02-11

1278


